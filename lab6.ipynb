{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6, Самсонов Савелий Артёмович М8О-406Б-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kuzushiji-MNIST (KMNIST) — это набор данных, содержащий изображения японских курсивных символов из классической литературы, представленные в том же формате, что и известный MNIST (28x28 пикселей, оттенки серого, 10 классов). Вот ключевые направления, где он может быть полезен на практике:\n",
    "\n",
    "1. Распознавание исторических рукописей (OCR для архивных документов)\n",
    "\n",
    "    Многие японские исторические тексты написаны курсивом (Kuzushiji), который сложен для автоматического распознавания. Современные OCR (Tesseract, ABBYY) плохо работают с такими символами.\n",
    "\n",
    "    Возможное применение KMNIST:\n",
    "    - Оцифровка архивов библиотек (Национальная Diet Library Японии) или музеев.\n",
    "\n",
    "2. Поддержка исследований в Digital Humanities\n",
    "\n",
    "    Лингвисты и историки анализируют рукописи вручную, что требует огромного времени.\n",
    "    \n",
    "    Возможное применение KMNIST:\n",
    "    - Автоматическая категоризация символов в больших корпусах текстов (например, поиск цитат из классической литературы).\n",
    "    - Визуальный поиск по стилю написания (аналогично тому, как работают поисковики по искусству).\n",
    "\n",
    "3. Тестирование robustness моделей CV\n",
    "\n",
    "    Современные классификаторы часто переобучаются на \"идеальных\" данных (типа MNIST), но падают в реальных условиях (размытые, наклонные символы).\n",
    "    \n",
    "    Возможное применение KMNIST:\n",
    "    - Валидация моделей для сценариев с \"шумными\" данными (например, распознавание рукописных медицинских форм или подписей).\n",
    "    - Сравнение методов аугментации (эластичные деформации, добавление фона)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор метрик для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Accuracy, измеряет долю правильно классифицированных экземпляров от общего числа примеров. Простая и понятная метрика, но может давать ошибочное представление для несбалансированных классов (когда классы имеют существенно отличающееся количество экземпляров).\n",
    "2. Precision, измеряет долю правильных положительных предсказаний среди всех предсказанных положительных примеров.\n",
    "3. Recall, измеряет долю правильно предсказанных положительных примеров среди всех реальных положительных примеров.\n",
    "Precision, Recall важны в случае несбалансированных классов и при необходимости минимизировать ложные срабатывания.\n",
    "4. F1-мера, является гармоническим средним между точностью и полнотой и используется для сбалансирования этих двух метрик. Комбинирует точность и полноту, идеально подходит для несбалансированных задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Создание бейзлайна и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение сверточной модели и оценка качества по выбранным метрикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Изменяем размер изображений до 224x224, так как ResNet ожидает такие размеры\n",
    "    transforms.Grayscale(num_output_channels=3),  # Конвертируем изображение в 3 канала (RGB), т.к. ResNet работает с 3 каналами\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.KMNIST(root='./data2', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.KMNIST(root='./data2', train=False, download=True, transform=transform)\n",
    "\n",
    "subset_size = 30000\n",
    "train_subset = Subset(trainset, range(subset_size))\n",
    "\n",
    "trainloader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/5], Потери: 0.1373, Точность: 95.74%\n",
      "Эпоха [2/5], Потери: 0.0432, Точность: 98.65%\n",
      "Эпоха [3/5], Потери: 0.0353, Точность: 98.89%\n",
      "Эпоха [4/5], Потери: 0.0191, Точность: 99.39%\n",
      "Эпоха [5/5], Потери: 0.0216, Точность: 99.29%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss/len(trainloader):.4f}, Точность: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9691\n",
      "Precision: 0.9701\n",
      "Recall: 0.9691\n",
      "F1-score: 0.9691\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение трансформерной модели и оценка качества по выбранным метрикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_trans = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # преобразуем в 3 канала, как для RGB изображений\n",
    "    transforms.Resize((224, 224)),  # размер изображения для ViT\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "trainset_trans = torchvision.datasets.KMNIST(root='./data3', train=True, download=True, transform=transform_trans)\n",
    "testset_trans = torchvision.datasets.KMNIST(root='./data3', train=False, download=True, transform=transform_trans)\n",
    "\n",
    "subset_size = 5000\n",
    "train_subset_trans = Subset(trainset_trans, range(subset_size))\n",
    "subset_size = 2000\n",
    "test_subset_trans = Subset(testset_trans, range(subset_size))\n",
    "\n",
    "trainloader_trans = DataLoader(train_subset_trans, batch_size=16, shuffle=True)\n",
    "testloader_trans = DataLoader(test_subset_trans, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_trans = models.vit_b_16(pretrained=True)\n",
    "model_trans.heads.head = nn.Linear(model_trans.heads.head.in_features, 10)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_trans = model_trans.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_trans.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/5], Потери: 2.2242, Точность: 16.30%\n",
      "Эпоха [2/5], Потери: 2.1328, Точность: 20.28%\n",
      "Эпоха [3/5], Потери: 1.9567, Точность: 27.10%\n",
      "Эпоха [4/5], Потери: 1.7911, Точность: 34.06%\n",
      "Эпоха [5/5], Потери: 1.6813, Точность: 38.56%\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_trans.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in trainloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model_trans(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss/len(trainloader_trans):.4f}, Точность: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3140\n",
      "Precision: 0.3752\n",
      "Recall: 0.3140\n",
      "F1-score: 0.3125\n"
     ]
    }
   ],
   "source": [
    "model_trans.eval()\n",
    "\n",
    "all_labels_trans = []\n",
    "all_preds_trans = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_trans(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels_trans.extend(labels.cpu().numpy())\n",
    "        all_preds_trans.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy_trans = accuracy_score(all_labels_trans, all_preds_trans)\n",
    "precision_trans = precision_score(all_labels_trans, all_preds_trans, average='weighted')\n",
    "recall_trans = recall_score(all_labels_trans, all_preds_trans, average='weighted')\n",
    "f1_trans = f1_score(all_labels_trans, all_preds_trans, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy_trans:.4f}')\n",
    "print(f'Precision: {precision_trans:.4f}')\n",
    "print(f'Recall: {recall_trans:.4f}')\n",
    "print(f'F1-score: {f1_trans:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Аугментация данных\n",
    "\n",
    "    Аугментация данных может значительно улучшить способность модели обобщать, снижая вероятность переобучения. Можно добавить следующие виды аугментации:\n",
    "    - Геометрические преобразования: вращение, сдвиг, масштабирование, изменение перспективы.\n",
    "    - Шум: добавление гауссовского шума или случайных искажений.\n",
    "    - Зеркальные отражения или случайные обрезки.\n",
    "\n",
    "2. Использование дополнительных слоев\n",
    "\n",
    "    Можно добавить дополнительные слои для извлечения более сложных признаков. Например, можно добавить слой Batch Normalization перед слоями активации или добавить несколько полносвязных слоев в конце сети для улучшения классификации. Добавление слоев Dropout в модель может помочь избежать чрезмерного подгона модели под тренировочные данные.\n",
    "\n",
    "\n",
    "3. Смена оптимизатора:\n",
    "\n",
    "    В данный момент используется Adam, но можно попробовать другие оптимизаторы, например, SGD с моментумом. Adam хорошо работает в большинстве случаев, но иногда SGD может привести к лучшему результату."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Свёрточная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Аугментация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # Вращение на случайный угол в пределах 10 градусов\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Случайный сдвиг по осям\n",
    "    transforms.RandomHorizontalFlip(),  # Случайное горизонтальное отражение\n",
    "    transforms.Resize(224),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trainset = torchvision.datasets.KMNIST(root='./data5', train=True, download=True, transform=new_transform)\n",
    "new_testset = torchvision.datasets.KMNIST(root='./data5', train=False, download=True, transform=new_transform)\n",
    "\n",
    "subset_size = 30000\n",
    "new_train_subset = Subset(new_trainset, range(subset_size))\n",
    "\n",
    "new_trainloader = DataLoader(new_train_subset, batch_size=64, shuffle=True)\n",
    "new_testloader = DataLoader(new_testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = models.resnet18(pretrained=True)\n",
    "new_model.fc = nn.Linear(new_model.fc.in_features, 10)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "new_model = new_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(new_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/5], Потери: 0.2579, Точность: 91.95%\n",
      "Эпоха [2/5], Потери: 0.1086, Точность: 96.55%\n",
      "Эпоха [3/5], Потери: 0.0820, Точность: 97.51%\n",
      "Эпоха [4/5], Потери: 0.0643, Точность: 97.93%\n",
      "Эпоха [5/5], Потери: 0.0560, Точность: 98.21%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    new_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in new_trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = new_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss/len(new_trainloader):.4f}, Точность: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9363\n",
      "Precision: 0.9379\n",
      "Recall: 0.9363\n",
      "F1-score: 0.9363\n"
     ]
    }
   ],
   "source": [
    "new_model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in new_testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = new_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Дополнительные слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "new_model = models.resnet18(pretrained=True)\n",
    "new_model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.BatchNorm1d(new_model.fc.in_features),\n",
    "    nn.Linear(new_model.fc.in_features, 10)\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "new_model = new_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(new_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/5], Потери: 0.1521, Точность: 95.60%\n",
      "Эпоха [2/5], Потери: 0.0551, Точность: 98.30%\n",
      "Эпоха [3/5], Потери: 0.0298, Точность: 99.13%\n",
      "Эпоха [4/5], Потери: 0.0228, Точность: 99.28%\n",
      "Эпоха [5/5], Потери: 0.0268, Точность: 99.15%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    new_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = new_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss/len(trainloader):.4f}, Точность: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9618\n",
      "Precision: 0.9624\n",
      "Recall: 0.9618\n",
      "F1-score: 0.9617\n"
     ]
    }
   ],
   "source": [
    "new_model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = new_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = models.resnet18(pretrained=True)\n",
    "new_model.fc = nn.Linear(new_model.fc.in_features, 10)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "new_model = new_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(new_model.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/5], Потери: 0.4565, Точность: 87.92%\n",
      "Эпоха [2/5], Потери: 0.0888, Точность: 97.84%\n",
      "Эпоха [3/5], Потери: 0.0461, Точность: 99.02%\n",
      "Эпоха [4/5], Потери: 0.0275, Точность: 99.48%\n",
      "Эпоха [5/5], Потери: 0.0178, Точность: 99.76%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    new_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = new_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss/len(trainloader):.4f}, Точность: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9574\n",
      "Precision: 0.9580\n",
      "Recall: 0.9574\n",
      "F1-score: 0.9573\n"
     ]
    }
   ],
   "source": [
    "new_model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = new_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка гипотез не принесла улучшений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Трансформерная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Аугментация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18.2M/18.2M [00:16<00:00, 1.10MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 138kB/s]\n",
      "100%|██████████| 3.04M/3.04M [00:04<00:00, 683kB/s] \n",
      "100%|██████████| 5.12k/5.12k [00:00<00:00, 9.71MB/s]\n"
     ]
    }
   ],
   "source": [
    "new_transform_trans = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # Вращение на случайный угол в пределах 10 градусов\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Случайный сдвиг по осям\n",
    "    transforms.RandomHorizontalFlip(),  # Случайное горизонтальное отражение\n",
    "\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "new_trainset_trans = torchvision.datasets.KMNIST(root='./data8', train=True, download=True, transform=new_transform_trans)\n",
    "new_testset_trans = torchvision.datasets.KMNIST(root='./data8', train=False, download=True, transform=new_transform_trans)\n",
    "\n",
    "subset_size = 5000\n",
    "new_train_subset_trans = Subset(new_trainset_trans, range(subset_size))\n",
    "subset_size = 2000\n",
    "new_test_subset_trans = Subset(new_testset_trans, range(subset_size))\n",
    "\n",
    "new_trainloader_trans = DataLoader(new_train_subset_trans, batch_size=16, shuffle=True)\n",
    "new_testloader_trans = DataLoader(new_test_subset_trans, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_trans = models.vit_b_16(pretrained=True)\n",
    "model_trans.heads.head = nn.Linear(model_trans.heads.head.in_features, 10)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_trans = model_trans.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_trans.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/5], Потери: 2.4101, Точность: 10.30%\n",
      "Эпоха [2/5], Потери: 2.3509, Точность: 10.46%\n",
      "Эпоха [3/5], Потери: 2.3346, Точность: 11.00%\n",
      "Эпоха [4/5], Потери: 2.3116, Точность: 10.98%\n",
      "Эпоха [5/5], Потери: 2.2888, Точность: 12.36%\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_trans.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in new_trainloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model_trans(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss/len(new_trainloader_trans):.4f}, Точность: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1560\n",
      "Precision: 0.0841\n",
      "Recall: 0.1560\n",
      "F1-score: 0.0968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_trans.eval()\n",
    "\n",
    "all_labels_trans = []\n",
    "all_preds_trans = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in new_testloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_trans(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels_trans.extend(labels.cpu().numpy())\n",
    "        all_preds_trans.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy_trans = accuracy_score(all_labels_trans, all_preds_trans)\n",
    "precision_trans = precision_score(all_labels_trans, all_preds_trans, average='weighted')\n",
    "recall_trans = recall_score(all_labels_trans, all_preds_trans, average='weighted')\n",
    "f1_trans = f1_score(all_labels_trans, all_preds_trans, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy_trans:.4f}')\n",
    "print(f'Precision: {precision_trans:.4f}')\n",
    "print(f'Recall: {recall_trans:.4f}')\n",
    "print(f'F1-score: {f1_trans:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_trans = models.vit_b_16(pretrained=True)\n",
    "\n",
    "model_trans.heads.head = nn.Linear(model_trans.heads.head.in_features, 10)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_trans = model_trans.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model_trans.parameters(), lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/5], Потери: 2.3534, Точность: 12.12%\n",
      "Эпоха [2/5], Потери: 2.2498, Точность: 14.62%\n",
      "Эпоха [3/5], Потери: 2.1256, Точность: 19.84%\n",
      "Эпоха [4/5], Потери: 1.9146, Точность: 29.38%\n",
      "Эпоха [5/5], Потери: 1.8086, Точность: 34.06%\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_trans.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in trainloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model_trans(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss/len(trainloader_trans):.4f}, Точность: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2895\n",
      "Precision: 0.3610\n",
      "Recall: 0.2895\n",
      "F1-score: 0.2746\n"
     ]
    }
   ],
   "source": [
    "model_trans.eval()\n",
    "\n",
    "all_labels_trans = []\n",
    "all_preds_trans = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_trans(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels_trans.extend(labels.cpu().numpy())\n",
    "        all_preds_trans.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy_trans = accuracy_score(all_labels_trans, all_preds_trans)\n",
    "precision_trans = precision_score(all_labels_trans, all_preds_trans, average='weighted')\n",
    "recall_trans = recall_score(all_labels_trans, all_preds_trans, average='weighted')\n",
    "f1_trans = f1_score(all_labels_trans, all_preds_trans, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy_trans:.4f}')\n",
    "print(f'Precision: {precision_trans:.4f}')\n",
    "print(f'Recall: {recall_trans:.4f}')\n",
    "print(f'F1-score: {f1_trans:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка гипотез не принесла улучшений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить результаты не удалось.\n",
    "\n",
    "Сверточная модель и так очень точна, и её версии с примененными улучшениями выдают примерно те же результаты.\n",
    "\n",
    "Трансформерная модель, по все видимости, слишком мало обучалась. Для скорости обучения было взято малое число эпох, для улучшения результатов необходимо, как минимум, увеличить его."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Имплементация алгоритма машинного обучения "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "cust_trainset = torchvision.datasets.KMNIST(root='./data6', train=True, download=True, transform=transform)\n",
    "cust_testset = torchvision.datasets.KMNIST(root='./data6', train=False, download=True, transform=transform)\n",
    "\n",
    "subset_size = 30000\n",
    "cust_train_subset = Subset(cust_trainset, range(subset_size))\n",
    "\n",
    "cust_trainloader = DataLoader(cust_train_subset, batch_size=64, shuffle=True)\n",
    "cust_testloader = DataLoader(cust_testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, шаг 100, потери: 0.950\n",
      "Эпоха 1, шаг 200, потери: 0.366\n",
      "Эпоха 1, шаг 300, потери: 0.248\n",
      "Эпоха 1, шаг 400, потери: 0.206\n",
      "Эпоха 2, шаг 100, потери: 0.127\n",
      "Эпоха 2, шаг 200, потери: 0.113\n",
      "Эпоха 2, шаг 300, потери: 0.106\n",
      "Эпоха 2, шаг 400, потери: 0.111\n",
      "Эпоха 3, шаг 100, потери: 0.066\n",
      "Эпоха 3, шаг 200, потери: 0.068\n",
      "Эпоха 3, шаг 300, потери: 0.070\n",
      "Эпоха 3, шаг 400, потери: 0.062\n",
      "Эпоха 4, шаг 100, потери: 0.037\n",
      "Эпоха 4, шаг 200, потери: 0.037\n",
      "Эпоха 4, шаг 300, потери: 0.039\n",
      "Эпоха 4, шаг 400, потери: 0.043\n",
      "Эпоха 5, шаг 100, потери: 0.022\n",
      "Эпоха 5, шаг 200, потери: 0.024\n",
      "Эпоха 5, шаг 300, потери: 0.024\n",
      "Эпоха 5, шаг 400, потери: 0.027\n"
     ]
    }
   ],
   "source": [
    "cust_model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cust_model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(cust_trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = cust_model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'Эпоха {epoch + 1}, шаг {i + 1}, потери: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.93\n",
      "Точность (Precision): 0.93\n",
      "Полнота (Recall): 0.93\n",
      "F1-Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cust_testloader:\n",
    "        outputs = cust_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Точность: {accuracy:.2f}')\n",
    "print(f'Точность (Precision): {precision:.2f}')\n",
    "print(f'Полнота (Recall): {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Трансформерная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10, embed_dim=768, num_heads=8, num_layers=6, hidden_dim=2048):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, embed_dim, kernel_size=16, stride=16)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 14*14 + 1, embed_dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            dim_feedforward=hidden_dim\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(x.size(0), -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding\n",
    "\n",
    "        x = self.transformer(x, x)\n",
    "\n",
    "        x = x[:, 0]\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_transform_trans = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "cust_trainset_trans = torchvision.datasets.KMNIST(root='./data3', train=True, download=True, transform=cust_transform_trans)\n",
    "cust_testset_trans = torchvision.datasets.KMNIST(root='./data3', train=False, download=True, transform=cust_transform_trans)\n",
    "\n",
    "subset_size = 5000\n",
    "cust_train_subset_trans = Subset(cust_trainset_trans, range(subset_size))\n",
    "subset_size = 2000\n",
    "cust_test_subset_trans = Subset(cust_testset_trans, range(subset_size))\n",
    "\n",
    "cust_trainloader_trans = DataLoader(cust_train_subset_trans, batch_size=16, shuffle=True)\n",
    "cust_testloader_trans = DataLoader(cust_test_subset_trans, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/5], Потери: 2.5110, Точность: 10.36%\n",
      "Эпоха [2/5], Потери: 2.3785, Точность: 9.38%\n",
      "Эпоха [3/5], Потери: 2.3394, Точность: 9.38%\n",
      "Эпоха [4/5], Потери: 2.3240, Точность: 9.86%\n",
      "Эпоха [5/5], Потери: 2.3200, Точность: 10.48%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cust_model_trans = TransformerClassifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cust_model_trans.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    cust_model_trans.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in cust_trainloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = cust_model_trans(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss/len(cust_trainloader_trans):.4f}, Точность: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.11\n",
      "Точность (Precision): 0.01\n",
      "Полнота (Recall): 0.11\n",
      "F1-Score: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "cust_model_trans.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cust_testloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = cust_model_trans(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Точность: {accuracy:.2f}')\n",
    "print(f'Точность (Precision): {precision:.2f}')\n",
    "print(f'Полнота (Recall): {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты имплементированной сверточной модели близки к результатам встроенной модели.\n",
    "\n",
    "Как и в случае встроенных версий, трансормерная имплементированная модель получилась менее эффективной, чем сверточная, но с большей разницей, чем у встроенных версий. В целом, иного и не ожидалось в виду простоты имплементированной версии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Улучшения для имплементированных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сверточная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Аугментация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),  # Поворот изображения на случайный угол\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Сдвиг изображения\n",
    "    transforms.RandomHorizontalFlip(),  # Отражение по горизонтали\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18.2M/18.2M [00:10<00:00, 1.70MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 111kB/s]\n",
      "100%|██████████| 3.04M/3.04M [00:03<00:00, 810kB/s] \n",
      "100%|██████████| 5.12k/5.12k [00:00<00:00, 5.15MB/s]\n"
     ]
    }
   ],
   "source": [
    "new_cust_trainset = torchvision.datasets.KMNIST(root='./data7', train=True, download=True, transform=new_transform)\n",
    "new_cust_testset = torchvision.datasets.KMNIST(root='./data7', train=False, download=True, transform=new_transform)\n",
    "\n",
    "subset_size = 30000\n",
    "new_cust_train_subset = Subset(new_cust_trainset, range(subset_size))\n",
    "\n",
    "new_cust_trainloader = DataLoader(new_cust_train_subset, batch_size=64, shuffle=True)\n",
    "new_cust_testloader = DataLoader(new_cust_testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, шаг 100, потери: 1.547\n",
      "Эпоха 1, шаг 200, потери: 0.985\n",
      "Эпоха 1, шаг 300, потери: 0.796\n",
      "Эпоха 1, шаг 400, потери: 0.738\n",
      "Эпоха 2, шаг 100, потери: 0.572\n",
      "Эпоха 2, шаг 200, потери: 0.501\n",
      "Эпоха 2, шаг 300, потери: 0.467\n",
      "Эпоха 2, шаг 400, потери: 0.456\n",
      "Эпоха 3, шаг 100, потери: 0.388\n",
      "Эпоха 3, шаг 200, потери: 0.382\n",
      "Эпоха 3, шаг 300, потери: 0.361\n",
      "Эпоха 3, шаг 400, потери: 0.351\n",
      "Эпоха 4, шаг 100, потери: 0.324\n",
      "Эпоха 4, шаг 200, потери: 0.307\n",
      "Эпоха 4, шаг 300, потери: 0.301\n",
      "Эпоха 4, шаг 400, потери: 0.288\n",
      "Эпоха 5, шаг 100, потери: 0.266\n",
      "Эпоха 5, шаг 200, потери: 0.264\n",
      "Эпоха 5, шаг 300, потери: 0.263\n",
      "Эпоха 5, шаг 400, потери: 0.253\n"
     ]
    }
   ],
   "source": [
    "new_cust_model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(new_cust_model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(new_cust_trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = new_cust_model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'Эпоха {epoch + 1}, шаг {i + 1}, потери: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.83\n",
      "Точность (Precision): 0.83\n",
      "Полнота (Recall): 0.83\n",
      "F1-Score: 0.83\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in new_cust_testloader:\n",
    "        outputs = new_cust_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Точность: {accuracy:.2f}')\n",
    "print(f'Точность (Precision): {precision:.2f}')\n",
    "print(f'Полнота (Recall): {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Добавление слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, шаг 100, потери: 1.113\n",
      "Эпоха 1, шаг 200, потери: 0.563\n",
      "Эпоха 1, шаг 300, потери: 0.445\n",
      "Эпоха 1, шаг 400, потери: 0.393\n",
      "Эпоха 2, шаг 100, потери: 0.329\n",
      "Эпоха 2, шаг 200, потери: 0.315\n",
      "Эпоха 2, шаг 300, потери: 0.276\n",
      "Эпоха 2, шаг 400, потери: 0.293\n",
      "Эпоха 3, шаг 100, потери: 0.238\n",
      "Эпоха 3, шаг 200, потери: 0.260\n",
      "Эпоха 3, шаг 300, потери: 0.239\n",
      "Эпоха 3, шаг 400, потери: 0.220\n",
      "Эпоха 4, шаг 100, потери: 0.213\n",
      "Эпоха 4, шаг 200, потери: 0.187\n",
      "Эпоха 4, шаг 300, потери: 0.197\n",
      "Эпоха 4, шаг 400, потери: 0.208\n",
      "Эпоха 5, шаг 100, потери: 0.167\n",
      "Эпоха 5, шаг 200, потери: 0.178\n",
      "Эпоха 5, шаг 300, потери: 0.169\n",
      "Эпоха 5, шаг 400, потери: 0.169\n"
     ]
    }
   ],
   "source": [
    "new_cust_model = ImprovedCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(new_cust_model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(cust_trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = new_cust_model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'Эпоха {epoch + 1}, шаг {i + 1}, потери: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.87\n",
      "Точность (Precision): 0.87\n",
      "Полнота (Recall): 0.87\n",
      "F1-Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cust_testloader:\n",
    "        outputs = new_cust_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Точность: {accuracy:.2f}')\n",
    "print(f'Точность (Precision): {precision:.2f}')\n",
    "print(f'Полнота (Recall): {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, шаг 100, потери: 2.259\n",
      "Эпоха 1, шаг 200, потери: 2.035\n",
      "Эпоха 1, шаг 300, потери: 1.397\n",
      "Эпоха 1, шаг 400, потери: 0.938\n",
      "Эпоха 2, шаг 100, потери: 0.699\n",
      "Эпоха 2, шаг 200, потери: 0.680\n",
      "Эпоха 2, шаг 300, потери: 0.609\n",
      "Эпоха 2, шаг 400, потери: 0.576\n",
      "Эпоха 3, шаг 100, потери: 0.529\n",
      "Эпоха 3, шаг 200, потери: 0.470\n",
      "Эпоха 3, шаг 300, потери: 0.441\n",
      "Эпоха 3, шаг 400, потери: 0.433\n",
      "Эпоха 4, шаг 100, потери: 0.383\n",
      "Эпоха 4, шаг 200, потери: 0.401\n",
      "Эпоха 4, шаг 300, потери: 0.345\n",
      "Эпоха 4, шаг 400, потери: 0.327\n",
      "Эпоха 5, шаг 100, потери: 0.303\n",
      "Эпоха 5, шаг 200, потери: 0.292\n",
      "Эпоха 5, шаг 300, потери: 0.290\n",
      "Эпоха 5, шаг 400, потери: 0.271\n"
     ]
    }
   ],
   "source": [
    "new_cust_model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(new_cust_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(cust_trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = new_cust_model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'Эпоха {epoch + 1}, шаг {i + 1}, потери: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.83\n",
      "Точность (Precision): 0.83\n",
      "Полнота (Recall): 0.83\n",
      "F1-Score: 0.83\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cust_testloader:\n",
    "        outputs = new_cust_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Точность: {accuracy:.2f}')\n",
    "print(f'Точность (Precision): {precision:.2f}')\n",
    "print(f'Полнота (Recall): {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка гипотез не принесла улучшений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Трансформерная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Аугментация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cust_transform_trans = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # Вращение на случайный угол в пределах 10 градусов\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Случайный сдвиг по осям\n",
    "    transforms.RandomHorizontalFlip(),  # Случайное горизонтальное отражение\n",
    "\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "new_cust_trainset_trans = torchvision.datasets.KMNIST(root='./data8', train=True, download=True, transform=new_cust_transform_trans)\n",
    "new_cust_testset_trans = torchvision.datasets.KMNIST(root='./data8', train=False, download=True, transform=new_cust_transform_trans)\n",
    "\n",
    "subset_size = 5000\n",
    "new_cust_train_subset_trans = Subset(new_cust_trainset_trans, range(subset_size))\n",
    "subset_size = 2000\n",
    "new_cust_test_subset_trans = Subset(new_cust_testset_trans, range(subset_size))\n",
    "\n",
    "new_cust_trainloader_trans = DataLoader(new_cust_train_subset_trans, batch_size=16, shuffle=True)\n",
    "new_cust_testloader_trans = DataLoader(new_cust_test_subset_trans, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/5], Потери: 2.4720, Точность: 10.28%\n",
      "Эпоха [2/5], Потери: 2.3785, Точность: 10.46%\n",
      "Эпоха [3/5], Потери: 2.3504, Точность: 10.06%\n",
      "Эпоха [4/5], Потери: 2.3319, Точность: 9.92%\n",
      "Эпоха [5/5], Потери: 2.3211, Точность: 9.62%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "new_cust_model_trans = TransformerClassifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(new_cust_model_trans.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    new_cust_model_trans.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in new_cust_trainloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = new_cust_model_trans(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss/len(new_cust_trainloader_trans):.4f}, Точность: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.10\n",
      "Точность (Precision): 0.01\n",
      "Полнота (Recall): 0.10\n",
      "F1-Score: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "new_cust_model_trans.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in new_cust_testloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = new_cust_model_trans(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Точность: {accuracy:.2f}')\n",
    "print(f'Точность (Precision): {precision:.2f}')\n",
    "print(f'Полнота (Recall): {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "new_cust_model_trans = TransformerClassifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.AdamW(new_cust_model_trans.parameters(), lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/5], Потери: 2.4765, Точность: 10.22%\n",
      "Эпоха [2/5], Потери: 2.3742, Точность: 9.26%\n",
      "Эпоха [3/5], Потери: 2.3383, Точность: 10.62%\n",
      "Эпоха [4/5], Потери: 2.3179, Точность: 10.44%\n",
      "Эпоха [5/5], Потери: 2.3163, Точность: 9.38%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    new_cust_model_trans.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in cust_trainloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = new_cust_model_trans(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Эпоха [{epoch+1}/{num_epochs}], Потери: {running_loss/len(cust_trainloader_trans):.4f}, Точность: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.11\n",
      "Точность (Precision): 0.01\n",
      "Полнота (Recall): 0.11\n",
      "F1-Score: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "new_cust_model_trans.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cust_testloader_trans:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = new_cust_model_trans(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Точность: {accuracy:.2f}')\n",
    "print(f'Точность (Precision): {precision:.2f}')\n",
    "print(f'Полнота (Recall): {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка гипотез не принесла улучшений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично ситуации со встроенными моделями, улучшений не вышло.\n",
    "\n",
    "Сверточная модель и без того обладает высокой точностью, трансформерной модели требуется серьезное улучшение архитектуры и большее обучение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
